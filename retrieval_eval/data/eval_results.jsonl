{"query_id": "982V2ituTdc_0", "query": "what is error analysis in ai", "gold_video_id": "982V2ituTdc", "retrieved_ids": ["982V2ituTdc", "1pQ_JNItjdo", "_tFXHsNKWS8"], "scores": [-4.924579668416234, -3.945560582145554, -3.8772040817835727], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "982V2ituTdc_1", "query": "why llm outputs change each time same question", "gold_video_id": "982V2ituTdc", "retrieved_ids": ["3PIqhdRzhxE", "eC6Hd1hFvos"], "scores": [-2.97127798124973, -2.5061599906056173], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "982V2ituTdc_2", "query": "how is error analysis not the same for LLM vs normal ai", "gold_video_id": "982V2ituTdc", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "982V2ituTdc_3", "query": "steps to do error analysis for ai app", "gold_video_id": "982V2ituTdc", "retrieved_ids": ["1pQ_JNItjdo", "ayGdRbMDZcU", "889wd07LcFs"], "scores": [-6.140007485712849, -5.901669654349861, -3.4722743202272484], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "982V2ituTdc_4", "query": "add auto checks for failed cases in LLM error cycle", "gold_video_id": "982V2ituTdc", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "982V2ituTdc_5", "query": "stuck on putting error subtypez, is there fast shortcut?", "gold_video_id": "982V2ituTdc", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "5ezFcy9CIWE_0", "query": "persistent homology definition", "gold_video_id": "5ezFcy9CIWE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "5ezFcy9CIWE_1", "query": "h0 h1 h2 homology groups meaning", "gold_video_id": "5ezFcy9CIWE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "5ezFcy9CIWE_2", "query": "persistance diagram axes units?", "gold_video_id": "5ezFcy9CIWE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "5ezFcy9CIWE_3", "query": "can wasserstein distances actually predict market crashes?", "gold_video_id": "5ezFcy9CIWE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "5ezFcy9CIWE_4", "query": "persistent homology python code with market data", "gold_video_id": "5ezFcy9CIWE", "retrieved_ids": ["5ezFcy9CIWE", "NlMrvCYlOOQ"], "scores": [-19.50637129573767, -9.520920263570051], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "5ezFcy9CIWE_5", "query": "how big should my time window be for reliable persistent homology (finance)", "gold_video_id": "5ezFcy9CIWE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "3PIqhdRzhxE_0", "query": "What is the mlx library used in local LLM fine-tuning on Mac?", "gold_video_id": "3PIqhdRzhxE", "retrieved_ids": ["3PIqhdRzhxE"], "scores": [-20.373858245412944], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "3PIqhdRzhxE_1", "query": "7b param lora on mac m1 8gb any chance or need for swapfile?", "gold_video_id": "3PIqhdRzhxE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "3PIqhdRzhxE_2", "query": "fine-tuning small vs big Macs is it worth it?", "gold_video_id": "3PIqhdRzhxE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "3PIqhdRzhxE_3", "query": "How do I set up environment for mlx finetuning on mac m1?", "gold_video_id": "3PIqhdRzhxE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "3PIqhdRzhxE_4", "query": "mlx training crashes on batch size 4, running out of memory", "gold_video_id": "3PIqhdRzhxE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "3PIqhdRzhxE_5", "query": "after mlx finetune on apple, how save full model and move to hf hub?", "gold_video_id": "3PIqhdRzhxE", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "MX7ymkYGiZ0_0", "query": "what is a wavelet transform", "gold_video_id": "MX7ymkYGiZ0", "retrieved_ids": ["MX7ymkYGiZ0", "-5c1KO-JF_s", "rPUytg38b6Q"], "scores": [-11.861653086125541, -10.080312130240339, -9.539194938468773], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "MX7ymkYGiZ0_1", "query": "continuous vs discrete wavelets difference", "gold_video_id": "MX7ymkYGiZ0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "MX7ymkYGiZ0_2", "query": "b param meaning in gauss wavelet eqn", "gold_video_id": "MX7ymkYGiZ0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "MX7ymkYGiZ0_3", "query": "why use wavelets instead of fourier", "gold_video_id": "MX7ymkYGiZ0", "retrieved_ids": ["MX7ymkYGiZ0", "-5c1KO-JF_s"], "scores": [-14.017126490263667, -12.594695254676028], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "MX7ymkYGiZ0_4", "query": "time freq tradeoff in wavelet transform", "gold_video_id": "MX7ymkYGiZ0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "MX7ymkYGiZ0_5", "query": "does picking sym4 change how well i find peaks", "gold_video_id": "MX7ymkYGiZ0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "BOPOX_mTS0g_0", "query": "outcome vs treatment vs covariate variables", "gold_video_id": "BOPOX_mTS0g", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "BOPOX_mTS0g_1", "query": "ITE and ATT diff?", "gold_video_id": "BOPOX_mTS0g", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "BOPOX_mTS0g_2", "query": "difference between RCTs and observational data in causal studies", "gold_video_id": "BOPOX_mTS0g", "retrieved_ids": ["BOPOX_mTS0g"], "scores": [-21.41580597213699], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "BOPOX_mTS0g_3", "query": "counterfatual is just guess right? how accurate can it get?", "gold_video_id": "BOPOX_mTS0g", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "BOPOX_mTS0g_4", "query": "how to calculate average treatment effect in randomized controlled trial", "gold_video_id": "BOPOX_mTS0g", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "BOPOX_mTS0g_5", "query": "include multiple covariants, will affect causal results?", "gold_video_id": "BOPOX_mTS0g", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "0iFEtnHyzE0_0", "query": "definition of fine-tuning in machine learning", "gold_video_id": "0iFEtnHyzE0", "retrieved_ids": ["4RAvJt3fWoI", "OLmKFj-_5Uw", "tFHeUSJAYbE"], "scores": [-4.452051135861147, -4.4179265340806015, -4.386567635208196], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "0iFEtnHyzE0_1", "query": "is chat gtp a finetunned model or something else?", "gold_video_id": "0iFEtnHyzE0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "0iFEtnHyzE0_2", "query": "why do we need to fine-tune a pre-trained model?", "gold_video_id": "0iFEtnHyzE0", "retrieved_ids": ["hOLBrIjRAj4", "eC6Hd1hFvos", "bbVoDXoPrPM"], "scores": [-5.90285333772653, -5.611674677896308, -5.322218829554532], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "0iFEtnHyzE0_3", "query": "so fine tuning lets u change the models behavoir for tasks?", "gold_video_id": "0iFEtnHyzE0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "0iFEtnHyzE0_4", "query": "how to make a specialized gpt chatbot using finetune", "gold_video_id": "0iFEtnHyzE0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "0iFEtnHyzE0_5", "query": "training my own instructgpt process error: model runs forever", "gold_video_id": "0iFEtnHyzE0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "0cf7vzM_dZ0_0", "query": "definition of prompt engineering", "gold_video_id": "0cf7vzM_dZ0", "retrieved_ids": ["OLmKFj-_5Uw", "tFHeUSJAYbE", "0cf7vzM_dZ0"], "scores": [-6.030141441312387, -5.989372318365784, -5.244181129717558], "gold_rank": 3, "rr": 0.3333333333333333, "hit@1": 0, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "0cf7vzM_dZ0_1", "query": "prompt engineering heuristic not science?", "gold_video_id": "0cf7vzM_dZ0", "retrieved_ids": ["ZLbVdvOoTKM"], "scores": [-5.280120178750556], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "0cf7vzM_dZ0_2", "query": "when do i need better prompts vs finetune model", "gold_video_id": "0cf7vzM_dZ0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "0cf7vzM_dZ0_3", "query": "why does my prompt sometimes fail if i have too much info in", "gold_video_id": "0cf7vzM_dZ0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "0cf7vzM_dZ0_4", "query": "automatic grading with python prompt example", "gold_video_id": "0cf7vzM_dZ0", "retrieved_ids": ["0cf7vzM_dZ0"], "scores": [-12.193099732418155], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "0cf7vzM_dZ0_5", "query": "my output parser returns false alwasys, what did i miss", "gold_video_id": "0cf7vzM_dZ0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "4RAvJt3fWoI_0", "query": "Difference between AI chatbot and assistant", "gold_video_id": "4RAvJt3fWoI", "retrieved_ids": ["qPrVqTIkobg", "3JsgtpX_rpU"], "scores": [-9.113124257448193, -5.624635643573556], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "4RAvJt3fWoI_1", "query": "Why can't I just embed the assistant on my site?", "gold_video_id": "4RAvJt3fWoI", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "4RAvJt3fWoI_2", "query": "finetune or prompt tricking for custom style?", "gold_video_id": "4RAvJt3fWoI", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "4RAvJt3fWoI_3", "query": "How do I connect to OpenAI Assistants API using python?", "gold_video_id": "4RAvJt3fWoI", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "4RAvJt3fWoI_4", "query": "how uploade many documents to rag for faster runs?", "gold_video_id": "4RAvJt3fWoI", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "4RAvJt3fWoI_5", "query": "wait_for_assistant stuck at client.beta.threads.runs.retrieve, no error? help", "gold_video_id": "4RAvJt3fWoI", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "4QHg8Ix8WWQ_0", "query": "what is masked language modeling in bert?", "gold_video_id": "4QHg8Ix8WWQ", "retrieved_ids": ["4QHg8Ix8WWQ", "YOvxh_ma5qE"], "scores": [-19.972186209342542, -16.086695668849703], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "4QHg8Ix8WWQ_1", "query": "what does parameter freezing mean in transfer learning?", "gold_video_id": "4QHg8Ix8WWQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "4QHg8Ix8WWQ_2", "query": "how do you avoid overfitting when fine-tuning bert?", "gold_video_id": "4QHg8Ix8WWQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "4QHg8Ix8WWQ_3", "query": "using smaller models vs huge llms for common nlp taks", "gold_video_id": "4QHg8Ix8WWQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "4QHg8Ix8WWQ_4", "query": "is BERT a LLM like chatgpt or only for text tasks?", "gold_video_id": "4QHg8Ix8WWQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "4QHg8Ix8WWQ_5", "query": "bert too slow to train on cpu, how to make faster", "gold_video_id": "4QHg8Ix8WWQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "6VcXukJuGA0_0", "query": "What are the three types of evals for LLM feedback loops?", "gold_video_id": "6VcXukJuGA0", "retrieved_ids": ["6VcXukJuGA0"], "scores": [-12.859683913898282], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "6VcXukJuGA0_1", "query": "is reward hacking like when a model just spams for high metrics?", "gold_video_id": "6VcXukJuGA0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "6VcXukJuGA0_2", "query": "picking evals for LLM loops, what should I focus on?", "gold_video_id": "6VcXukJuGA0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "6VcXukJuGA0_3", "query": "can optimizing for feedback in loops make LLMs act weird or bad?", "gold_video_id": "6VcXukJuGA0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "6VcXukJuGA0_4", "query": "Run LLM feedback loop script locally", "gold_video_id": "6VcXukJuGA0", "retrieved_ids": ["889wd07LcFs"], "scores": [-8.238346025113737], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "6VcXukJuGA0_5", "query": "how to generate automatic feedback msg, not just copy errors", "gold_video_id": "6VcXukJuGA0", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "3JsgtpX_rpU_0", "query": "explain how text embeddings turn resume info into numbers", "gold_video_id": "3JsgtpX_rpU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "3JsgtpX_rpU_1", "query": "why are llms unpredictable for business applications?", "gold_video_id": "3JsgtpX_rpU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "3JsgtpX_rpU_2", "query": "saving money on api calls vs model accuracy ai business tasks typo", "gold_video_id": "3JsgtpX_rpU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "GgLaP4Des1Q_0", "query": "ica statisitcal independence definition", "gold_video_id": "GgLaP4Des1Q", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "GgLaP4Des1Q_1", "query": "why non-gausian data needed for ica eeg", "gold_video_id": "GgLaP4Des1Q", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "GgLaP4Des1Q_2", "query": "difference between pca and ica results in eeg", "gold_video_id": "GgLaP4Des1Q", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "GgLaP4Des1Q_3", "query": "do we always pca first before independent component analise?", "gold_video_id": "GgLaP4Des1Q", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "GgLaP4Des1Q_4", "query": "how to remove blink artifact from eeg using ica", "gold_video_id": "GgLaP4Des1Q", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "GgLaP4Des1Q_5", "query": "restoring eeg original data after ica/pca?", "gold_video_id": "GgLaP4Des1Q", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "Nm_mmRTpWLg_0", "query": "LLM workflow definition in simple terms?", "gold_video_id": "Nm_mmRTpWLg", "retrieved_ids": ["ZaY5_ScmiFE", "OLmKFj-_5Uw"], "scores": [-9.556192440372824, -6.760031058127203], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "Nm_mmRTpWLg_1", "query": "agentic workflow vs rule based whats the main difference?", "gold_video_id": "Nm_mmRTpWLg", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "Nm_mmRTpWLg_2", "query": "is code or prompt better for making the computer do stuff", "gold_video_id": "Nm_mmRTpWLg", "retrieved_ids": ["hugQUr4VwRA", "3PIqhdRzhxE", "w-Ml3NivoFo"], "scores": [-3.455768319589934, -3.142349108690669, -3.1170052611570935], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "Nm_mmRTpWLg_3", "query": "What are the weak points of LLM workflows?", "gold_video_id": "Nm_mmRTpWLg", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "Nm_mmRTpWLg_4", "query": "when should i pick llms over just writing code manually?", "gold_video_id": "Nm_mmRTpWLg", "retrieved_ids": ["ayGdRbMDZcU", "bbVoDXoPrPM", "uZvR1tG4Dng"], "scores": [-4.7709579711514545, -4.426050950528543, -3.021872840731114], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "Nm_mmRTpWLg_5", "query": "llm chain feedback loops open ended flow - what does that mean?", "gold_video_id": "Nm_mmRTpWLg", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "B6a64wdD7Zs_0", "query": "decision tree definition simple terms", "gold_video_id": "B6a64wdD7Zs", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "B6a64wdD7Zs_1", "query": "what is gini impurity formula", "gold_video_id": "B6a64wdD7Zs", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "B6a64wdD7Zs_2", "query": "why is overfitting a problem for decision trees", "gold_video_id": "B6a64wdD7Zs", "retrieved_ids": ["ZaXpMou55lw", "B6a64wdD7Zs", "BUTjcAjfMgY"], "scores": [-13.6480247063002, -13.22612694799072, -8.137572377351828], "gold_rank": 2, "rr": 0.5, "hit@1": 0, "hit@3": 1, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "B6a64wdD7Zs_3", "query": "does splitting on every value always better or not?", "gold_video_id": "B6a64wdD7Zs", "retrieved_ids": ["B6a64wdD7Zs", "ZaY5_ScmiFE", "XpoKB3usmKc"], "scores": [-4.934618564475114, -3.1583685687195646, -2.6127388591675524], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "B6a64wdD7Zs_4", "query": "how to oversmaple data with smote typo", "gold_video_id": "B6a64wdD7Zs", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "B6a64wdD7Zs_5", "query": "train test model split keeps giving error in pandas", "gold_video_id": "B6a64wdD7Zs", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "6qCrvlHRhcM_0", "query": "Difference between rules in traditional software and machine learning", "gold_video_id": "6qCrvlHRhcM", "retrieved_ids": ["6qCrvlHRhcM", "Nm_mmRTpWLg"], "scores": [-7.0164480674737515, -6.58004054594664], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "6qCrvlHRhcM_1", "query": "embedding vector for transcript is always 384 or 768?", "gold_video_id": "6qCrvlHRhcM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "6qCrvlHRhcM_2", "query": "Why is machine learning model development considered iterative?", "gold_video_id": "6qCrvlHRhcM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "6qCrvlHRhcM_3", "query": "if I summarize before embedding, does that mean less noise or missing info?", "gold_video_id": "6qCrvlHRhcM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "6qCrvlHRhcM_4", "query": "setting correct threshold for search result in semantic system", "gold_video_id": "6qCrvlHRhcM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "6qCrvlHRhcM_5", "query": "polers scanparet failes on huge file, how fix memory issuw", "gold_video_id": "6qCrvlHRhcM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "N3vHJcHBS-w_0", "query": "what is Model Context Protocol", "gold_video_id": "N3vHJcHBS-w", "retrieved_ids": ["XEMZniYKuaY", "rTkm1eY0ezU", "N3vHJcHBS-w"], "scores": [-3.69872109256978, -3.689700147329051, -3.365190176409148], "gold_rank": 3, "rr": 0.3333333333333333, "hit@1": 0, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "N3vHJcHBS-w_1", "query": "mcp server primitives prompt vs resource", "gold_video_id": "N3vHJcHBS-w", "retrieved_ids": ["N3vHJcHBS-w"], "scores": [-24.091540372851416], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "N3vHJcHBS-w_2", "query": "how mcp sends promt to llm", "gold_video_id": "N3vHJcHBS-w", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "N3vHJcHBS-w_3", "query": "why use mcp instead of building custom integration for every app", "gold_video_id": "N3vHJcHBS-w", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "N3vHJcHBS-w_4", "query": "moving my assistant tools from vscode to other IDEs", "gold_video_id": "N3vHJcHBS-w", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "N3vHJcHBS-w_5", "query": "difference mcp server and clinet which runs the tools?", "gold_video_id": "N3vHJcHBS-w", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "-AA0xw5xeQU_0", "query": "How do you extract video ID for YouTube to blog tool?", "gold_video_id": "-AA0xw5xeQU", "retrieved_ids": ["tMiQIxSX64c", "OnIQrDiTtRM", "-AA0xw5xeQU"], "scores": [-7.657262682381723, -7.548876179972038, -7.416383776933957], "gold_rank": 3, "rr": 0.3333333333333333, "hit@1": 0, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "-AA0xw5xeQU_1", "query": "text embedding mean what in vector db context", "gold_video_id": "-AA0xw5xeQU", "retrieved_ids": ["QvxuR8uLPFs"], "scores": [-8.985304194016162], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "-AA0xw5xeQU_2", "query": "Is ollama actually an LLM or just a wrapper thing", "gold_video_id": "-AA0xw5xeQU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "-AA0xw5xeQU_3", "query": "make a gradio chat interface for local pdf QAs", "gold_video_id": "-AA0xw5xeQU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "-AA0xw5xeQU_4", "query": "survey clustering responses python steps?", "gold_video_id": "-AA0xw5xeQU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "-AA0xw5xeQU_5", "query": "Can't upload jsonl file to open AI finetune, getting format errror", "gold_video_id": "-AA0xw5xeQU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "4vvoIA0MalQ_0", "query": "feature importance in tree ensemble models definition", "gold_video_id": "4vvoIA0MalQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "4vvoIA0MalQ_1", "query": "tree ensembles explaination, why so hard to see inside?", "gold_video_id": "4vvoIA0MalQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "4vvoIA0MalQ_2", "query": "why use fewer features in a model?", "gold_video_id": "4vvoIA0MalQ", "retrieved_ids": ["eC6Hd1hFvos"], "scores": [-6.1578315270566595], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "4vvoIA0MalQ_3", "query": "hand-picked bins vs tree buckets differences", "gold_video_id": "4vvoIA0MalQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "4vvoIA0MalQ_4", "query": "how do you split 1 feature into multiple labels with trees?", "gold_video_id": "4vvoIA0MalQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "4vvoIA0MalQ_5", "query": "percent alive column, how is it calcualted?", "gold_video_id": "4vvoIA0MalQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "8z-WPpP1_-8_0", "query": "What does AI mean in simple terms?", "gold_video_id": "8z-WPpP1_-8", "retrieved_ids": ["8z-WPpP1_-8", "BUTjcAjfMgY", "6qCrvlHRhcM"], "scores": [-2.6316806443154297, -2.2805774107975902, -2.1548889716523174], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "8z-WPpP1_-8_1", "query": "is lern machine just pattern recog?", "gold_video_id": "8z-WPpP1_-8", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "8z-WPpP1_-8_2", "query": "mental models vs computer models for desicions", "gold_video_id": "8z-WPpP1_-8", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "8z-WPpP1_-8_3", "query": "steps to get started putting AI into my business", "gold_video_id": "8z-WPpP1_-8", "retrieved_ids": ["Xn_Zw6KSxYU", "e3p9-hYxwSQ", "uZvR1tG4Dng"], "scores": [-4.570442596678791, -4.124814162802753, -3.331056721581434], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "8z-WPpP1_-8_4", "query": "improve client emails with 70 percent AI trick?", "gold_video_id": "8z-WPpP1_-8", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "8z-WPpP1_-8_5", "query": "wont AI stuff just need huge team or expensve servers", "gold_video_id": "8z-WPpP1_-8", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "-BUs1CPHKfU_0", "query": "What are the basic steps needed to enable LLMs to use tools?", "gold_video_id": "-BUs1CPHKfU", "retrieved_ids": ["Sx_MwcBQGOg"], "scores": [-5.924825923054595], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "-BUs1CPHKfU_1", "query": "agents SDK agent structure", "gold_video_id": "-BUs1CPHKfU", "retrieved_ids": ["-BUs1CPHKfU", "Nm_mmRTpWLg", "Sx_MwcBQGOg"], "scores": [-13.144354090282876, -12.383551645028238, -10.239853458566518], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "-BUs1CPHKfU_2", "query": "Does using @function_tool always work? Missing when API settings change?", "gold_video_id": "-BUs1CPHKfU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "-BUs1CPHKfU_3", "query": "agentic workflows versus regular software logic", "gold_video_id": "-BUs1CPHKfU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "-BUs1CPHKfU_4", "query": "When would you need to custom-train for complicated tool use?", "gold_video_id": "-BUs1CPHKfU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "-BUs1CPHKfU_5", "query": "why are agents sometimes so unpredictable, is this a llm limit or tools mix up?", "gold_video_id": "-BUs1CPHKfU", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "889wd07LcFs_0", "query": "What is UV in the context of Python projects?", "gold_video_id": "889wd07LcFs", "retrieved_ids": ["889wd07LcFs", "vEvytl7wrGM"], "scores": [-6.866417806632798, -4.801343053253267], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "889wd07LcFs_1", "query": "local db storage for agent, chromadb necessary?", "gold_video_id": "889wd07LcFs", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "889wd07LcFs_2", "query": "letting agent decide retrieval or use rules: what\u2019s better?", "gold_video_id": "889wd07LcFs", "retrieved_ids": ["889wd07LcFs"], "scores": [-12.620088373936893], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "889wd07LcFs_3", "query": "is llm just a folder for prompts or does it mean large language model is running local?", "gold_video_id": "889wd07LcFs", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "889wd07LcFs_4", "query": "How do you start coding with Claude Code CLI in Cursor?", "gold_video_id": "889wd07LcFs", "retrieved_ids": ["889wd07LcFs", "V1BR2tb_e8g"], "scores": [-12.78883809781282, -12.533899704357731], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "889wd07LcFs_5", "query": "uv add openai not creating venv file, what\u2019s wrong?", "gold_video_id": "889wd07LcFs", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "NlMrvCYlOOQ_0", "query": "reducing dimenstion with pca or umap in mapper", "gold_video_id": "NlMrvCYlOOQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "NlMrvCYlOOQ_1", "query": "in python code where do u define the cover for mappr?", "gold_video_id": "NlMrvCYlOOQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "NlMrvCYlOOQ_2", "query": "why use the mapper algorithm for high dimensional datasets?", "gold_video_id": "NlMrvCYlOOQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "NlMrvCYlOOQ_3", "query": "is a node same as a datapoint or a cluster lol", "gold_video_id": "NlMrvCYlOOQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "NlMrvCYlOOQ_4", "query": "how do I export the mapper result as html?", "gold_video_id": "NlMrvCYlOOQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "NlMrvCYlOOQ_5", "query": "add manifold iso map before umap mapper how?", "gold_video_id": "NlMrvCYlOOQ", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "03x2oYg9oME_0", "query": "why use a proof of concept in DS projects", "gold_video_id": "03x2oYg9oME", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "03x2oYg9oME_1", "query": "feedback loops importance in project steps", "gold_video_id": "03x2oYg9oME", "retrieved_ids": ["ZaY5_ScmiFE"], "scores": [-6.720471602913413], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "03x2oYg9oME_2", "query": "If fullstack ds, can one person do all roles? Should you?", "gold_video_id": "03x2oYg9oME", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "03x2oYg9oME_3", "query": "deploying semantic search with API and Docker", "gold_video_id": "03x2oYg9oME", "retrieved_ids": ["pJ_nCklQ65w", "xm9devSQEqU", "03x2oYg9oME"], "scores": [-13.89644979871541, -11.99652981327109, -10.24366060206487], "gold_rank": 3, "rr": 0.3333333333333333, "hit@1": 0, "hit@3": 1, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "03x2oYg9oME_4", "query": "elt pipline for youtube videos?", "gold_video_id": "03x2oYg9oME", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "03x2oYg9oME_5", "query": "project eval not matching outcomes, what to adjust (due dates?)", "gold_video_id": "03x2oYg9oME", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "FLkUOkeMd5M_0", "query": "Can these smaller models run on a laptop or limited RAM machines?", "gold_video_id": "FLkUOkeMd5M", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "medium"}
{"query_id": "FLkUOkeMd5M_1", "query": "distil bert same as a LLM or not?", "gold_video_id": "FLkUOkeMd5M", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "exact", "difficulty": "hard"}
{"query_id": "FLkUOkeMd5M_2", "query": "Why can compressing an LLM sometimes improve its performance?", "gold_video_id": "FLkUOkeMd5M", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "FLkUOkeMd5M_3", "query": "tradeoff between size reduction and accuracy in compression?", "gold_video_id": "FLkUOkeMd5M", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "FLkUOkeMd5M_4", "query": "How do you combine knowledge distillation with quantization using hugging face and pytorch?", "gold_video_id": "FLkUOkeMd5M", "retrieved_ids": ["FLkUOkeMd5M"], "scores": [-29.23831404521297], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "validation", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "FLkUOkeMd5M_5", "query": "loss and evaluate for more than 2 class task, code confuses me", "gold_video_id": "FLkUOkeMd5M", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "validation", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "15Kd9OPn7tw_0", "query": "What is the power law tail index and how does it measure fat tails?", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": ["15Kd9OPn7tw", "Wcqt49dXtm8"], "scores": [-31.212592685510977, -27.589516326704512], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "test", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "15Kd9OPn7tw_1", "query": "curtosis vs skew for fat tail distinction", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "medium"}
{"query_id": "15Kd9OPn7tw_2", "query": "lognormal parametres, how does sigma related to the tail?", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "hard"}
{"query_id": "15Kd9OPn7tw_3", "query": "How do fat tails differ between gaussian, log-normal and Pareto distributions?", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "15Kd9OPn7tw_4", "query": "Are high kurtosis values always proof of fat tails?", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "15Kd9OPn7tw_5", "query": "is Kappa better than alpa or kurtos for quantifing outliers", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "15Kd9OPn7tw_6", "query": "How do I calculate kurtosis for a dataset in Python?", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "15Kd9OPn7tw_7", "query": "plotting log-histrogram for fat tailed data", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "15Kd9OPn7tw_8", "query": "mad sample error, Kappa calculation doesnt match example output", "gold_video_id": "15Kd9OPn7tw", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "1pQ_JNItjdo_0", "query": "llm tutor make from youtube video transcripts?", "gold_video_id": "1pQ_JNItjdo", "retrieved_ids": ["vEvytl7wrGM"], "scores": [-11.315325041982193], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "hard"}
{"query_id": "1pQ_JNItjdo_1", "query": "why use vector database for education agent", "gold_video_id": "1pQ_JNItjdo", "retrieved_ids": ["1pQ_JNItjdo"], "scores": [-11.305193822504679], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "test", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "1pQ_JNItjdo_2", "query": "evals for ai content generator, why needed?", "gold_video_id": "1pQ_JNItjdo", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "1pQ_JNItjdo_3", "query": "RAG vs these agents, when better to combine?", "gold_video_id": "1pQ_JNItjdo", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "1pQ_JNItjdo_4", "query": "how to link chatgpt with notion for search", "gold_video_id": "1pQ_JNItjdo", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "1pQ_JNItjdo_5", "query": "my agent never passes all evals, what fix?", "gold_video_id": "1pQ_JNItjdo", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "BUTjcAjfMgY_0", "query": "definition of world model in ml", "gold_video_id": "BUTjcAjfMgY", "retrieved_ids": ["xm9devSQEqU", "03x2oYg9oME", "pJ_nCklQ65w"], "scores": [-5.466713576862378, -5.213592642045796, -4.659857061220373], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "BUTjcAjfMgY_1", "query": "what makes feature engineering less important with neural nets", "gold_video_id": "BUTjcAjfMgY", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "medium"}
{"query_id": "BUTjcAjfMgY_2", "query": "loss fn vs reward what\u2019s diff", "gold_video_id": "BUTjcAjfMgY", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "hard"}
{"query_id": "BUTjcAjfMgY_3", "query": "why does rl optimize for reward instead of accuracy", "gold_video_id": "BUTjcAjfMgY", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "BUTjcAjfMgY_4", "query": "shallow vs deep layers what\u2019s the diff", "gold_video_id": "BUTjcAjfMgY", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "BUTjcAjfMgY_5", "query": "is deep learning also ai? or just upgraded ML?", "gold_video_id": "BUTjcAjfMgY", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "-5c1KO-JF_s_0", "query": "What is wavelet smoothing in time series analysis?", "gold_video_id": "-5c1KO-JF_s", "retrieved_ids": ["-5c1KO-JF_s"], "scores": [-14.069788467986658], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "test", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "-5c1KO-JF_s_1", "query": "Fourier and wavelet difference for signal clean up", "gold_video_id": "-5c1KO-JF_s", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "hard"}
{"query_id": "-5c1KO-JF_s_2", "query": "overfit with big window moving average or polynomial?", "gold_video_id": "-5c1KO-JF_s", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "-5c1KO-JF_s_3", "query": "Is polynome fitting just overkill? Should I use convolution filters instead?", "gold_video_id": "-5c1KO-JF_s", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "-5c1KO-JF_s_4", "query": "Function for applying wavelet smoothing to price data", "gold_video_id": "-5c1KO-JF_s", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "-5c1KO-JF_s_5", "query": "how do I run that github notebook for my own crypto data?", "gold_video_id": "-5c1KO-JF_s", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "-sL7QzDFW-4_0", "query": "what is a vibe check in llm evaluation?", "gold_video_id": "-sL7QzDFW-4", "retrieved_ids": ["-sL7QzDFW-4", "982V2ituTdc", "bbVoDXoPrPM"], "scores": [-10.03329944626374, -7.503576676530841, -7.317917291645429], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "test", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "-sL7QzDFW-4_1", "query": "llm judge bias problem summary", "gold_video_id": "-sL7QzDFW-4", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "hard"}
{"query_id": "-sL7QzDFW-4_2", "query": "why iterating prompts by just vibe checking isn\u2019t optimal", "gold_video_id": "-sL7QzDFW-4", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "-sL7QzDFW-4_3", "query": "llm as judge vs human grading benefits and risks", "gold_video_id": "-sL7QzDFW-4", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "-sL7QzDFW-4_4", "query": "using yt transcript api to get many vids?", "gold_video_id": "-sL7QzDFW-4", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "-sL7QzDFW-4_5", "query": "AI blogs suddenly worse after changing prompt, what is causing perf drop?", "gold_video_id": "-sL7QzDFW-4", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "hard"}
{"query_id": "ASU5HG5EqTM_0", "query": "What is identifiability in causal inference?", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": ["dejZzJIZdow"], "scores": [-13.96804617749708], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "grounded"}
{"query_id": "ASU5HG5EqTM_1", "query": "back door path meaning causal graph", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "exact", "difficulty": "medium"}
{"query_id": "ASU5HG5EqTM_2", "query": "is every DAG markovian? cycles or unmeasured confounders?", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": ["ASU5HG5EqTM"], "scores": [-30.034061859978628], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "test", "query_type": "exact", "difficulty": "hard"}
{"query_id": "ASU5HG5EqTM_3", "query": "When do you use front door vs back door criterion for identifiability?", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "grounded"}
{"query_id": "ASU5HG5EqTM_4", "query": "Why does conditioning on a collider change dependence between variables?", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "medium"}
{"query_id": "ASU5HG5EqTM_5", "query": "causal dag from data or do I draw it from my assumptions?", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "conceptual", "difficulty": "hard"}
{"query_id": "ASU5HG5EqTM_6", "query": "How to check if a set satisfies the front door criterion", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": ["ASU5HG5EqTM"], "scores": [-23.84428731262755], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "test", "query_type": "procedural", "difficulty": "grounded"}
{"query_id": "ASU5HG5EqTM_7", "query": "block backdoor paths: what do I do if I have a collider node?", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": ["ASU5HG5EqTM"], "scores": [-31.088218014390993], "gold_rank": 1, "rr": 1.0, "hit@1": 1, "hit@3": 1, "split": "test", "query_type": "procedural", "difficulty": "medium"}
{"query_id": "ASU5HG5EqTM_8", "query": "model stops being markovian \u2014 how fix unobserved variable issue?", "gold_video_id": "ASU5HG5EqTM", "retrieved_ids": [], "scores": [], "gold_rank": -1, "rr": 0.0, "hit@1": 0, "hit@3": 0, "split": "test", "query_type": "procedural", "difficulty": "hard"}
